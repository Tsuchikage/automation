{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_log_file(log_file_content):\n",
    "    # Создаем пустой DataFrame для заполнения таблицы\n",
    "    columns = [\"Test\", \"File\", \"Line\", \"Error Message\", \"@report.external_id\", \"@report.work_item_ids\"]\n",
    "    data = []\n",
    "    result_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    # Регулярное выражение для извлечения идентификаторов из строки вида \"@report.external_id('7e879e1e-9732-49af-bfea-e6f74f5a6627')\"\n",
    "    external_id_pattern = re.compile(r\"@report.external_id\\('([^']+)'\\)\")\n",
    "    work_item_ids_pattern = re.compile(r\"@report.work_item_ids\\('([^']+)'\\)\")\n",
    "\n",
    "    # Распарсим лог-файл\n",
    "    for line in log_file_content.split(\"\\n\"):\n",
    "        try:\n",
    "            if line.strip():  # Пропускаем пустые строки\n",
    "                log_entry = json.loads(line)\n",
    "                if log_entry.get(\"outcome\") == \"failed\":\n",
    "                    test_name = log_entry[\"nodeid\"]\n",
    "                    file_path = test_name.split(\"::\")[0]\n",
    "                    # Извлекаем имя теста (без пути и имени файла)\n",
    "                    test_name = test_name.split(\"::\")[-1]\n",
    "\n",
    "                    line_number = log_entry.get(\"location\", [])[1]\n",
    "                    error_message = log_entry[\"longrepr\"][\"reprcrash\"].get(\"message\", \"\")\n",
    "                    reprentries = log_entry[\"longrepr\"][\"reprtraceback\"].get(\"reprentries\", \"\")\n",
    "\n",
    "                    # Извлечение значений новых столбцов из log_entry\n",
    "                    external_id_match = external_id_pattern.search(line)\n",
    "                    external_id = external_id_match.group(1) if external_id_match else \"\"\n",
    "                    work_item_ids_match = work_item_ids_pattern.search(line)\n",
    "                    work_item_ids = work_item_ids_match.group(1) if work_item_ids_match else \"\"\n",
    "\n",
    "                    result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                        \"Test\": [test_name],\n",
    "                        \"File\": [file_path],\n",
    "                        \"Line\": [line_number],\n",
    "                        \"Error Message\": [error_message],\n",
    "                        \"@report.external_id\": [external_id],\n",
    "                        \"@report.work_item_ids\": [work_item_ids],\n",
    "                    })], ignore_index=True)\n",
    "        except (json.JSONDecodeError, TypeError, KeyError):\n",
    "            pass  # Пропускаем строки, которые не являются JSON или имеют неверный формат\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame сохранен в файл results_test.csv\n"
     ]
    }
   ],
   "source": [
    "log_file_path = \"results_test.log\" \n",
    "\n",
    "with open(log_file_path, \"r\") as log_file:\n",
    "    log_file_content = log_file.read()\n",
    "\n",
    "# Парсим лог-файл\n",
    "result_df = parse_log_file(log_file_content)\n",
    "\n",
    "# Сохраняем DataFrame в файл CSV\n",
    "result_df.to_csv(\"results_test.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"DataFrame сохранен в файл results_test.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
